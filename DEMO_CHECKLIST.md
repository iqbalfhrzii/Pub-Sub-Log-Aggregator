# üé¨ VIDEO DEMO CHECKLIST - UAS Sistem Terdistribusi

## Pub-Sub Log Aggregator dengan Idempotency & Transaksi

**‚è±Ô∏è Target: 20-25 menit | üìã 8 Poin Wajib Rubrik**

---

## üöÄ **PRE-RECORDING SETUP**

### **1. Persiapan Sistem**

```powershell
# Clean environment
docker compose down
docker system prune -f

# Setup database
python check_db.py
python test_exact_url.py

# Start Redis
docker compose up broker -d

# Start aggregator (biarkan running)
python simple_run.py
```

### **2. Test Koneksi**

```powershell
curl http://localhost:8081/health | ConvertFrom-Json | ConvertTo-Json -Depth 10
curl http://localhost:8081/stats | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

---

## üìã **POIN 1: ARSITEKTUR MULTI-SERVICE & ALASAN DESAIN**

**‚è±Ô∏è 3-4 menit**

### **Commands:**

```powershell
# Show project structure
tree /F

# Show docker-compose
code docker-compose.yml

# Show database schema
code aggregator/database.py
```

### **üìñ NARASI LENGKAP:**

> "Selamat datang di demo UAS Sistem Terdistribusi. Saya akan mendemonstrasikan Pub-Sub Log Aggregator dengan Idempotent Consumer.
>
> Mari kita lihat arsitektur sistem ini. Sistem terdiri dari 4 komponen utama yang berjalan dalam Docker Compose:
>
> **1. Aggregator Service** - Ini adalah API utama menggunakan FastAPI yang menerima dan memproses event. Service ini memiliki endpoint untuk publish event dan mengambil data.
>
> **2. Publisher Service** - Generator event yang dapat mensimulasikan duplikasi untuk testing idempotency.
>
> **3. PostgreSQL Database** - Database persisten yang menyimpan event dengan unique constraint pada kombinasi topic dan event_id untuk mencegah duplikasi.
>
> **4. Redis Broker** - Message broker untuk async processing dan queuing.
>
> Kenapa memilih arsitektur microservices? Karena memberikan separation of concerns, scalability, dan fault isolation. Setiap service punya tanggung jawab yang jelas.
>
> Di database.py, kita bisa lihat implementasi unique constraint (topic, event_id) yang menjadi kunci deduplication, dan penggunaan ACID transactions dengan isolation level READ_committed untuk mencegah race conditions."

---

## üìã **POIN 2: BUILD IMAGE & DOCKER COMPOSE**

**‚è±Ô∏è 4-5 menit**

### **Commands:**

```powershell
# Build and start (WAJIB DITAMPILKAN)
docker compose up --build -d

# Check status
docker compose ps

# Show aggregator running
# (sudah running dari setup)
```

### **üìñ NARASI LENGKAP:**

> "Sekarang mari kita lihat proses build dan deployment menggunakan Docker Compose.
>
> Perintah 'docker compose up --build -d' akan:
> **1. Build images** - Membuat Docker images untuk aggregator dan publisher services dari Dockerfile masing-masing
> **2. Create networks** - Membuat internal network untuk isolasi komunikasi antar services
> **3. Create volumes** - Membuat named volumes untuk persistensi data PostgreSQL dan Redis
> **4. Start containers** - Menjalankan semua services sesuai dependency order
>
> Dari 'docker compose ps' kita bisa lihat status semua containers. Yang penting diperhatikan:
>
> - **Named volumes** seperti postgres_data dan redis_data memastikan data tidak hilang meski container dihapus
> - **Internal network isolation** - semua komunikasi terjadi dalam network internal Docker, tidak ada akses ke layanan eksternal
> - **Security practices** - containers berjalan sebagai non-root user, menggunakan minimal base images
>
> Aggregator service sudah running di port 8081 dan siap menerima requests."

---

## üìã **POIN 3: IDEMPOTENCY & DUPLICATE DETECTION**

**‚è±Ô∏è 6-7 menit**

### **Commands:**

```powershell
# 1. Stats SEBELUM
curl http://localhost:8081/stats | ConvertFrom-Json | ConvertTo-Json -Depth 10

# 2. Event PERTAMA
curl -X POST http://localhost:8081/publish -H 'Content-Type: application/json' -d '{"topic":"demo","event_id":"test-001","timestamp":"2023-12-19T10:00:00Z","source":"test","payload":{"test":true}}' | ConvertFrom-Json | ConvertTo-Json -Depth 10

# 3. Event DUPLIKAT (SAMA PERSIS)
curl -X POST http://localhost:8081/publish -H 'Content-Type: application/json' -d '{"topic":"demo","event_id":"test-001","timestamp":"2023-12-19T10:00:00Z","source":"test","payload":{"test":true}}' | ConvertFrom-Json | ConvertTo-Json -Depth 10

# 4. Stats SESUDAH
curl http://localhost:8081/stats | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

### **üìñ NARASI LENGKAP:**

> "Sekarang kita akan mendemonstrasikan fitur utama sistem: Idempotency dan Duplicate Detection.
>
> **Langkah 1 - Statistik Awal:**
> Pertama, kita lihat statistik sistem sebelum ada event. Semua counter masih 0: received_count, unique_processed_count, duplicate_dropped_count.
>
> **Langkah 2 - Event Pertama:**
> Kita kirim event pertama dengan topic 'demo' dan event_id 'test-001'. Perhatikan response: 'processed: true' dan 'message: Event processed successfully'. Ini berarti event berhasil diproses dan disimpan ke database.
>
> **Langkah 3 - Event Duplikat:**
> Sekarang kita kirim event yang PERSIS SAMA - topic, event_id, timestamp, source, dan payload semuanya identik. Perhatikan response: 'processed: false' dan 'message: Duplicate event dropped'. Sistem mendeteksi ini adalah duplikat!
>
> **Langkah 4 - Statistik Akhir:**
> Mari kita lihat statistik setelah kedua event:
>
> - received_count: 2 (kedua event diterima)
> - unique_processed_count: 1 (hanya event pertama yang diproses)
> - duplicate_dropped_count: 1 (event kedua dideteksi sebagai duplikat)
>
> Ini membuktikan sistem memiliki **perfect idempotency** - event dengan (topic, event_id) yang sama hanya diproses sekali, meski diterima berkali-kali."

---

## üìã **POIN 4: TRANSAKSI & KONKURENSI MULTI-WORKER**

**‚è±Ô∏è 5-6 menit**

### **Commands:**

```powershell
# Concurrent test
python comprehensive_test.py

# Duplicate test
python debug_duplicate.py

# Show database transactions
code aggregator/database.py
# Highlight: isolation='read_committed', UniqueViolationError handling
```

### **üìñ NARASI LENGKAP:**

> "Sekarang kita akan mendemonstrasikan aspek paling kritis: Transaksi ACID dan Kontrol Konkurensi.
>
> **Concurrent Processing Test:**
> Script comprehensive_test.py menjalankan ThreadPoolExecutor dengan 5 workers yang mengirim events secara bersamaan. Ini mensimulasikan kondisi production dimana multiple clients mengirim events concurrent.
>
> Lihat hasilnya: semua events berhasil diproses tanpa race conditions atau data corruption. Sistem aman untuk concurrent access.
>
> **Duplicate Detection Under Concurrency:**
> Script debug_duplicate.py mengirim event yang sama dari multiple threads secara bersamaan. Hanya satu yang diproses, sisanya dideteksi sebagai duplikat.
>
> **Implementasi Transaksi:**
> Mari kita lihat kode di database.py:
>
> **1. Isolation Level:** Menggunakan 'read_committed' yang memberikan balance optimal antara consistency dan performance. Mencegah dirty reads tapi memungkinkan concurrent access.
>
> **2. Transaction Boundaries:** Setiap event processing dalam transaksi terpisah. Jika terjadi UniqueViolationError (duplikat), transaksi di-rollback dan counter duplikat di-update dalam transaksi baru.
>
> **3. Atomic Operations:** Insert event dan update statistics dilakukan dalam satu transaksi, memastikan consistency.
>
> **4. Race Condition Prevention:** Unique constraint di database level mencegah race conditions, bukan hanya application level.
>
> Ini membuktikan sistem memiliki **ACID compliance** yang proper dan **race condition free**."

---

## üìã **POIN 5: GET /events & /stats SEBELUM/SESUDAH**

**‚è±Ô∏è 2-3 menit**

### **üìñ NARASI PER TAHAP:**

> "Mari kita verifikasi data retrieval dan konsistensi statistics. Pertama kita ambil events yang telah diproses:"

```powershell
curl http://localhost:8081/events?limit=3 | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

> "Endpoint ini mengembalikan semua events yang telah diproses, diurutkan berdasarkan processed_at descending. Kita bisa lihat:
>
> - Event yang kita kirim tadi tersimpan dengan lengkap
> - Timestamp processing tercatat
> - Payload JSON tersimpan dengan benar
> - Metadata seperti topic, event_id, source semuanya akurat
>
> Sekarang kita test filtering berdasarkan topic:"

```powershell
curl 'http://localhost:8081/events?topic=demo&limit=2' | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

> "Dengan parameter ?topic=demo, sistem hanya mengembalikan events dengan topic 'demo'. Ini menunjukkan:
>
> - Query filtering berfungsi dengan baik
> - Database indexing optimal (ada index pada topic)
> - API response sesuai dengan filter yang diminta
>
> Terakhir, mari kita verifikasi konsistensi statistik:"

```powershell
curl http://localhost:8081/stats | ConvertFrom-Json | ConvertTo-Json -Depth 10
```

> "Statistik akhir menunjukkan konsistensi perfect:
>
> - Total received = unique processed + duplicates dropped
> - Topics count sesuai dengan jumlah topic unik
> - Uptime tracking berjalan dengan baik
> - Last updated timestamp akurat
>
> Ini membuktikan **data integrity** dan **API correctness** sistem."

---

## üìã **POIN 6: CRASH/RECREATE & DATA PERSISTEN**

**‚è±Ô∏è 4-5 menit**

### **Commands:**

```powershell
# 1. Stats SEBELUM restart
curl http://localhost:8081/stats | ConvertFrom-Json | ConvertTo-Json -Depth 10
curl http://localhost:8081/events?limit=2 | ConvertFrom-Json | ConvertTo-Json -Depth 10

# 2. Stop aggregator (Ctrl+C di terminal)
# 3. Restart database container
docker compose restart storage

# 4. Start aggregator lagi
python simple_run.py

# 5. Stats SETELAH restart (DATA MASIH ADA)
curl http://localhost:8081/stats | ConvertFrom-Json | ConvertTo-Json -Depth 10
curl http://localhost:8081/events?limit=2 | ConvertFrom-Json | ConvertTo-Json -Depth 10

# 6. Show volumes
docker volume ls
docker volume inspect uas_postgres_data
```

### **üìñ NARASI LENGKAP:**

> "Sekarang kita akan menguji aspek kritis: Crash Tolerance dan Data Persistence.
>
> **Data Sebelum Restart:**
> Mari kita catat data saat ini - ada beberapa events yang sudah diproses dan statistics yang sudah terakumulasi. Ini akan menjadi baseline untuk membuktikan persistensi.
>
> **Simulasi Crash:**
> Saya akan stop aggregator service dengan Ctrl+C untuk mensimulasikan crash aplikasi. Kemudian restart database container untuk mensimulasikan restart infrastruktur.
>
> **Restart System:**
> Sekarang saya start aggregator lagi dengan python simple_run.py. Sistem akan reconnect ke database yang sudah restart.
>
> **Verifikasi Data Persistence:**
> Mari kita check data setelah restart:
>
> - Statistics masih sama! received_count, unique_processed_count, duplicate_dropped_count semuanya preserved
> - Events masih ada semua dengan data lengkap
> - Tidak ada data loss sama sekali
>
> **Volume Inspection:**
> Perintah 'docker volume ls' menunjukkan named volumes yang kita gunakan. 'docker volume inspect uas_postgres_data' menunjukkan lokasi fisik data di host.
>
> **Mengapa Data Aman?**
>
> - **Named Volumes:** Data PostgreSQL disimpan di named volume, bukan di container filesystem
> - **Persistent Storage:** Volume tetap ada meski container dihapus/recreate
> - **ACID Durability:** PostgreSQL memastikan committed transactions survive crashes
>
> Ini membuktikan sistem memiliki **crash tolerance** dan **data durability** yang sempurna."

---

## üìã **POIN 7: KEAMANAN JARINGAN LOKAL**

**‚è±Ô∏è 2-3 menit**

### **Commands:**

```powershell
# Show networks
docker network ls

# Inspect internal network
docker network inspect uas_uas_network

# Show Dockerfile security
code aggregator/Dockerfile
```

### **üìñ NARASI LENGKAP:**

> "Mari kita verifikasi aspek keamanan sistem, khususnya network isolation dan container security.
>
> **Network Isolation:**
> Perintah 'docker network ls' menunjukkan network yang dibuat Docker Compose. Sistem menggunakan bridge network internal yang terisolasi.
>
> 'docker network inspect uas_uas_network' menunjukkan detail network:
>
> - **Internal Communication:** Semua containers berkomunikasi melalui network internal
> - **No External Access:** Tidak ada routing ke internet atau layanan eksternal
> - **Service Discovery:** Containers bisa saling akses menggunakan service names
> - **Port Isolation:** Hanya port yang di-expose yang bisa diakses dari host
>
> **Container Security:**
> Mari lihat Dockerfile aggregator:
>
> **1. Minimal Base Image:** Menggunakan python:3.11-slim yang minimal dan secure
> **2. Non-root User:** Container berjalan sebagai user 'appuser', bukan root
> **3. Dependency Management:** Hanya install dependencies yang diperlukan
> **4. Health Checks:** Built-in health check untuk monitoring
> **5. No Secrets:** Tidak ada hardcoded credentials atau secrets
>
> **Security Benefits:**
>
> - **Attack Surface Reduction:** Minimal components mengurangi vulnerability
> - **Privilege Separation:** Non-root execution mencegah privilege escalation
> - **Network Segmentation:** Internal network mencegah lateral movement
> - **Input Validation:** API melakukan validasi ketat pada semua input
>
> Sistem memenuhi **security best practices** untuk production deployment."

---

## üìã **POIN 8: OBSERVABILITY & KEPUTUSAN DESAIN**

**‚è±Ô∏è 3-4 menit**

### **Commands:**

```powershell
# Performance demo
python final_demo.py

# Show logs
# (dari terminal aggregator yang running)

# Database logs
docker compose logs storage --tail=10

# Show test results
python -m pytest tests/test_system.py::TestPubSubAggregator::test_event_deduplication -v
```

### **üìñ NARASI LENGKAP:**

> "Terakhir, mari kita lihat observability dan ringkasan keputusan desain sistem.
>
> **Performance Demonstration:**
> Script final_demo.py menunjukkan performa sistem dalam kondisi normal:
>
> - Throughput: >100 events/second
> - Deduplication rate: Perfect detection tanpa false positive/negative
> - Response time: <100ms per event
> - Memory usage: Efficient dengan connection pooling
>
> **Structured Logging:**
> Dari terminal aggregator, kita bisa lihat logs yang terstruktur:
>
> - **Timestamps:** Setiap log entry punya timestamp akurat
> - **Log Levels:** INFO untuk normal operations, ERROR untuk exceptions
> - **Event Processing:** Log untuk setiap event yang diproses atau di-drop
> - **Database Operations:** Log untuk connection dan transaction status
>
> **Database Monitoring:**
> PostgreSQL logs menunjukkan:
>
> - Connection establishment
> - Query execution
> - Transaction commits/rollbacks
> - Performance metrics
>
> **Comprehensive Testing:**
> Sistem dilengkapi 20 test cases yang mencakup:
>
> - Unit tests untuk individual functions
> - Integration tests untuk end-to-end flows
> - Concurrency tests untuk race conditions
> - Performance tests untuk throughput
> - Persistence tests untuk data durability
>
> **Key Design Decisions:**
>
> **1. Database Choice:** PostgreSQL untuk ACID compliance dan mature ecosystem
> **2. Isolation Level:** READ COMMITTED untuk balance consistency-performance
> **3. Deduplication Strategy:** Database unique constraints untuk atomicity
> **4. Architecture Pattern:** Microservices untuk scalability dan maintainability
> **5. Transaction Design:** Separate transactions untuk duplicates untuk avoid deadlocks
> **6. Error Handling:** Graceful degradation dengan proper exception handling
>
> **Production Readiness:**
>
> - Health checks untuk monitoring
> - Metrics untuk observability
> - Logging untuk debugging
> - Testing untuk reliability
> - Documentation untuk maintainability
>
> Sistem ini **production-ready** dengan semua aspek enterprise yang diperlukan."

---

## üéØ **KEPUTUSAN DESAIN SUMMARY**

### **Database:**

- PostgreSQL dengan unique constraints
- JSONB untuk flexible payload
- Proper indexing untuk performance

### **Transactions:**

- READ COMMITTED isolation
- Separate transactions untuk avoid deadlock
- Atomic operations untuk consistency

### **Architecture:**

- Microservices pattern
- Docker Compose orchestration
- Internal network security

### **Testing:**

- 20 test cases covering all scenarios
- Concurrent processing tests
- Performance benchmarking

---

## ‚úÖ **FINAL CHECKLIST**

**Sebelum Upload Video:**

- [ ] Semua 8 poin rubrik ditampilkan dengan narasi lengkap
- [ ] Commands berjalan tanpa error
- [ ] Audio/video quality bagus (1080p, clear audio)
- [ ] Durasi 20-25 menit (tidak lebih!)
- [ ] Narasi jelas, teknis, dan mudah dipahami
- [ ] Repository link dicantumkan di video description
- [ ] Slides untuk diagram arsitektur siap

**Repository Ready:**

- [ ] README.md lengkap dengan installation guide
- [ ] report.md dengan teori Bab 1-13 dan sitasi APA
- [ ] docker-compose.yml dengan named volumes
- [ ] 20 test cases dengan coverage lengkap
- [ ] Video link di README.md
- [ ] DEMO_CHECKLIST.md (file ini) untuk reference

**Files Yang Harus Ada:**

- [ ] aggregator/app_simple.py (main service)
- [ ] aggregator/database.py (ACID transactions)
- [ ] aggregator/Dockerfile (security practices)
- [ ] publisher/publisher.py (event generator)
- [ ] tests/test_system.py (20 comprehensive tests)
- [ ] comprehensive_test.py (concurrency demo)
- [ ] debug_duplicate.py (duplicate detection demo)
- [ ] final_demo.py (performance demo)
- [ ] simple_run.py (easy startup script)

---

## üé¨ **RECORDING TIPS**

1. **Setup Recording:**

   - 1080p resolution minimum
   - Clear audio (test microphone)
   - Clean desktop background
   - Close unnecessary apps

2. **During Demo:**

   - Speak clearly, not too fast
   - Explain every command
   - Show results clearly
   - Highlight key points

3. **Technical:**
   - Zoom in when showing code
   - Keep terminal text readable
   - Show full responses
   - Explain technical decisions

## üéØ **YANG PERLU ANDA BUAT SEBELUM RECORDING:**

### **1. Slides Presentasi (PowerPoint/Google Slides):**

- **Slide 1:** Judul + Nama + NIM
- **Slide 2:** Diagram Arsitektur (4 komponen)
- **Slide 3:** Fitur Utama (6 bullet points)
- **Slide 4:** Achievement Summary
- **Slide 5:** Technical Highlights
- **Slide 6:** Repository & Submission info

### **2. Test Semua Commands:**

```powershell
# Pastikan semua ini berjalan tanpa error:
python check_db.py
python simple_run.py
curl http://localhost:8081/health | ConvertFrom-Json | ConvertTo-Json -Depth 10
python comprehensive_test.py
python debug_duplicate.py
python final_demo.py
```

### **3. Recording Setup:**

- **Screen Resolution:** 1080p minimum
- **Audio:** Test microphone, clear sound
- **Desktop:** Clean background, close unnecessary apps
- **Browser:** Siapkan tab untuk slides
- **Terminal:** Font size besar, readable

### **4. Practice Run:**

- Baca narasi ini 1-2 kali
- Time setiap section (jangan over 25 menit total)
- Test semua commands sekali lagi
- Prepare backup plan jika ada command yang error

**üöÄ SETELAH SEMUA SIAP, ANDA READY TO RECORD!**
**Ikuti narasi ini word-by-word untuk hasil maksimal! üèÜ**
